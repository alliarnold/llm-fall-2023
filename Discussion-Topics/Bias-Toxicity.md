# Bias & Toxicity in LLM

### What is it?

**Bias** in LLM is the same as outside of LLM, a preference for or against a group of people, things, or characteristics. Where **toxicity** comes to play in LLM is as an outcome of the bias in the model, be it from the code, training technique, or the training corpus. **Bias** is the cause of **toxicity** in LLMs. As fruit can go from nutritious to sickening when it goes rancid, LLMs go from useful to dangerous when the biases in their base code and corpus are manifested by the wrong *application*.

### Why does it matter and why do we care

A LLM built on a biased corpus, if only ever used on a closed network, for specific training research, may never create a toxic result of a negative impact for the researchers interacting with the LLM. However, it will always have the potential to create toxic results and damaging impacts if released into the general world without guardrails or if given power over automated decisions that will impact others. 

The answer to why bias and toxicity in LLMs matter comes down to two key realities:

* we live in a capitalistic society
* words have power



### What do we do about
