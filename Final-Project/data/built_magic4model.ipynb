{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install transformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "#tqdm is a progress bar\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magic_4 = pd.read_csv('Final-Project/data/4answerdata.csv')\n",
    "magic_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c2n(answer):\n",
    "  if answer==\"Cannot predict now\":\n",
    "    return 0\n",
    "  elif answer==\"Outlook good\":\n",
    "    return 1\n",
    "  elif answer==\"Signs point to yes\":\n",
    "    return 2\n",
    "  else:\n",
    "    return 3\n",
    "\n",
    "magic_4['answer_4'] = magic_4['answer_4'].apply(c2n)\n",
    "magic_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magic_4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magic_4 = magic_4.sample(frac = 1) # shuffling order\n",
    "magic_4[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magic_4['answer_4'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = tokenizer.encode_plus(\n",
    "    magic_4['alli_q'].iloc[0],\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    "    add_special_tokens=True,\n",
    "    return_tensors=\"tf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input_ids = np.zeros((len(magic_4), 256))\n",
    "X_attn_masks = np.zeros((len(magic_4), 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(magic_4, ids, masks, tokenizer):\n",
    "  for i, text in tqdm(enumerate(magic_4['alli_q'])):\n",
    "    tokenized_text = tokenizer.encode_plus(\n",
    "        text,\n",
    "        max_length=256,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        add_special_tokens=True,\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "    ids[i,:] = tokenized_text.input_ids\n",
    "    masks[i,:] = tokenized_text.attention_mask\n",
    "  return ids, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input_ids, X_attn_masks = generate_training_data(magic_4, X_input_ids, X_attn_masks, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.zeros((len(magic_4), 4))\n",
    "\n",
    "# \"Cannot predict now\": 0\n",
    "# \"Outlook good\": 1\n",
    "# \"Signs point to yes\": 2\n",
    "# \"Outlook not good\": 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[np.arange(len(magic_4)), magic_4['answer_4'].values] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((X_input_ids, X_attn_masks, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  return {\n",
    "      'input_ids': input_ids,\n",
    "      'attention_mask': attn_masks\n",
    "  }, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(SentimentDatasetMapFunctions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(10000).batch(8, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using 80% for training, 20% for validation\n",
    "train_dataset = dataset.take(int((len(magic_4)//8)*.8))\n",
    "val_dataset= dataset.skip(int((len(magic_4)//8)*.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = TFBertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tf.keras.layers.Input(shape=(256,), name='input_ids', dtype='int32')\n",
    "attention_masks = tf.keras.layers.Input(shape=(256,), name='attention_mask', dtype='int32')\n",
    "\n",
    "bert_embds = bert_model.bert(input_ids, attention_mask=attention_masks)[1]\n",
    "intermediate_layer = tf.keras.layers.Dense(512, activation='relu', name='intermediate_layer')(bert_embds)\n",
    "output_layer = tf.keras.layers.Dense(4, activation='softmax', name='output_layer')(intermediate_layer)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_ids, attention_masks], outputs=output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using legacy Adam for mac\n",
    "optim = tf.keras.optimizers.legacy.Adam(learning_rate=1e-5, decay=1e-6)\n",
    "loss_func = tf.keras.losses.CategoricalCrossentropy()\n",
    "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optim, loss=loss_func, metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_models/magic4model')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
