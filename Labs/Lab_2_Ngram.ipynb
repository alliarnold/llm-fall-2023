{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQaTqAF3w5shuGxwK20lYu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Set Up"
      ],
      "metadata": {
        "id": "BwYGDoZ3IK9J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ2wbl2hUdoB",
        "outputId": "088cd4b4-3b4d-4e39-ffb5-7c23ba3ba7a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# load libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "from nltk import sent_tokenize\n",
        "from nltk.util import bigrams\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part I"
      ],
      "metadata": {
        "id": "VrTM4jtKISb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# leverage requests package to load in a text from project gutenberg\n",
        "# first do it with Prof's book\n",
        "\n",
        "r = requests.get(r'https://www.gutenberg.org/cache/epub/64317/pg64317.txt')\n",
        "great_gatsby = r.text\n",
        "\n",
        "# first, remove unwanted new line and tab characters from the text\n",
        "for char in [\"\\n\", \"\\r\", \"\\d\", \"\\t\"]:\n",
        "    great_gatsby = great_gatsby.replace(char, \" \")\n",
        "\n",
        "# check\n",
        "print(great_gatsby[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpSosUn2VRRq",
        "outputId": "afc860ec-b4ab-408b-b4e4-2e2a559984b6"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿The Project Gutenberg eBook of The Great Gatsby        This ebook is for the use of anyone anywhere\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# then trying it with my book selection [Sherlock Holmes] to see if results still work\n",
        "\n",
        "sh = requests.get(r'https://www.gutenberg.org/files/48320/48320-0.txt')\n",
        "sherlock_holmes = sh.text\n",
        "\n",
        "# first, remove unwanted new line and tab characters from the text\n",
        "for char in [\"\\n\", \"\\r\", \"\\d\", \"\\t\"]:\n",
        "    sherlock_holmes = sherlock_holmes.replace(char, \" \")\n",
        "\n",
        "# check that it worked and make sure to start at the top\n",
        "print(sherlock_holmes[3478:3750])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EvVOuy9Wj-g",
        "outputId": "c2d81e89-80e8-486b-b33f-d47e4f0892d4"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To Sherlock Holmes she is always _the_ woman. I have seldom heard  him mention her under any other name. In his eyes she eclipses and  predominates the whole of her sex. It was not that he felt any emotion  akin to love for Irene Adler. All emotions, and that one particul\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find the end\n",
        "sherlock_holmes.index(\"THE END\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRSadkKwYGPY",
        "outputId": "afda3e8d-819d-4dae-8798-3be85d1cccf8"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "592705"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# trim text to start of the bok\n",
        "sherlock_holmes = sherlock_holmes[3478:592705]\n",
        "print(sherlock_holmes[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYubzV3gYNea",
        "outputId": "dd6976b1-d1b2-4ee3-aaa5-07d7a2664bcf"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To Sherlock Holmes she is always _the_ woman. I have seldom heard  him mention her under any other n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# following steps for cleaning\n",
        "def clean_text(text: str):\n",
        "    # lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # remove punctuation from text\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "\n",
        "    # tokenize the text\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "\n",
        "    # return your tokens\n",
        "    return tokens\n",
        "\n",
        "# call the function\n",
        "sample_tokens = clean_text(text = sherlock_holmes)\n",
        "\n",
        "# check\n",
        "print(sample_tokens[:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5091zAiRHQmw",
        "outputId": "2a0ebc81-1c53-407d-a599-feceb6da1326"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['to', 'sherlock', 'holmes', 'she', 'is', 'always', '_the_', 'woman', 'i', 'have', 'seldom', 'heard', 'him', 'mention', 'her', 'under', 'any', 'other', 'name', 'in', 'his', 'eyes', 'she', 'eclipses', 'and', 'predominates', 'the', 'whole', 'of', 'her', 'sex', 'it', 'was', 'not', 'that', 'he', 'felt', 'any', 'emotion', 'akin', 'to', 'love', 'for', 'irene', 'adler', 'all', 'emotions', 'and', 'that', 'one']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create bigrams from the sample tokens\n",
        "my_bigrams = bigrams(sample_tokens)\n",
        "\n",
        "# check\n",
        "list(my_bigrams)[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuztjOtVH61r",
        "outputId": "69215718-023c-4027-96b0-42500295668a"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('to', 'sherlock'),\n",
              " ('sherlock', 'holmes'),\n",
              " ('holmes', 'she'),\n",
              " ('she', 'is'),\n",
              " ('is', 'always'),\n",
              " ('always', '_the_'),\n",
              " ('_the_', 'woman'),\n",
              " ('woman', 'i'),\n",
              " ('i', 'have'),\n",
              " ('have', 'seldom'),\n",
              " ('seldom', 'heard'),\n",
              " ('heard', 'him'),\n",
              " ('him', 'mention'),\n",
              " ('mention', 'her'),\n",
              " ('her', 'under'),\n",
              " ('under', 'any'),\n",
              " ('any', 'other'),\n",
              " ('other', 'name'),\n",
              " ('name', 'in'),\n",
              " ('in', 'his')]"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part II"
      ],
      "metadata": {
        "id": "Xuwxj0YoIGDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 is for bigrams\n",
        "n = 2\n",
        "#specify the text you want to use\n",
        "text = sherlock_holmes"
      ],
      "metadata": {
        "id": "NGyOkCCpIB_K"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step 1: tokenize the text into sentences\n",
        "sentences = nltk.sent_tokenize(text)\n",
        "\n",
        "# step 2: tokenize each sentence into words\n",
        "tokenized_sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
        "\n",
        "# step 3: convert each word to lowercase\n",
        "tokenized_text = [[word.lower() for word in sent] for sent in tokenized_sentences]\n",
        "\n",
        "#notice the sentence breaks and what the first 10 items of the tokenized text\n",
        "print(tokenized_text[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvFl8uWVIsjz",
        "outputId": "e9cb6276-5302-47b8-ae3e-220cb682d589"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['to', 'sherlock', 'holmes', 'she', 'is', 'always', '_the_', 'woman', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# notice what the first 10 items are of the vocabulary\n",
        "print(text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6r88ppJ1JRpA",
        "outputId": "1fb45e28-5d8c-4371-da42-15a2ee484cba"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To Sherlock Holmes she is always _the_ woman. I have seldom heard  him mention her under any other n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we imported this function from nltk\n",
        "train_data, padded_sents = padded_everygram_pipeline(n, tokenized_text)"
      ],
      "metadata": {
        "id": "uE_HysLPKBCd"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.lm import MLE\n",
        "# we imported this function from nltk linear models (lm)\n",
        "# it is for Maximum Likelihood Estimation\n",
        "\n",
        "# MLE is the model we will use\n",
        "lm = MLE(n)"
      ],
      "metadata": {
        "id": "YvlewouZKHtU"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# currently the vocab length is 0: it has no prior knowledge\n",
        "len(lm.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FGoA-ZjKLDa",
        "outputId": "7ba8baca-1f95-4a0b-a337-e7a0467cea64"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model\n",
        "# training data is the bigrams and unigrams\n",
        "# the vocab is all the sentence tokens in the corpus\n",
        "\n",
        "lm.fit(train_data, padded_sents)\n",
        "len(lm.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eJ2BuoKKMQP",
        "outputId": "5f051caa-fad2-4698-fbce-7db276e9813f"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9751"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect the model's vocabulary.\n",
        "# be sure that a sentence you know exists (from tokenized_text) is in the\n",
        "print(lm.vocab.lookup(tokenized_text[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xeUWdV3KQ0E",
        "outputId": "a6432248-bcc9-4f2c-cba8-c96f65a7c219"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('to', 'sherlock', 'holmes', 'she', 'is', 'always', '_the_', 'woman', '.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# see what happens when we include a word that is not in the vocab.\n",
        "print(lm.vocab.lookup('to sherlock holmes she is baobab .'.split()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IkkRvqpLwEA",
        "outputId": "00387dcb-9546-4820-d625-86dce361fec4"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('to', 'sherlock', 'holmes', 'she', 'is', '<UNK>', '.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how many times does bohemia appear in the model?\n",
        "print(lm.counts['bohemia'])\n",
        "\n",
        "# what is the probability of bohemia appearing?\n",
        "# this is technically the relative frequency of bohemia appearing\n",
        "lm.score('bohemia')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0iyPnOvMDt6",
        "outputId": "65191fc5-8320-4dc4-e3e8-57efa7286503"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.181186015066641e-05"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how often does (in, bohemia) occur and what is the relative frequency?\n",
        "print(lm.counts[['in']]['bohemia'])\n",
        "lm.score('in', 'bohemia'.split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRinDylvMRLA",
        "outputId": "262c1b75-8931-486e-e14f-26b8bdab1ed9"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.125"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# what is the score of 'UNK'?\n",
        "\n",
        "lm.score(\"<UNK>\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2MbktZrM3Wl",
        "outputId": "e45a51b1-2efd-498a-8b84-cdcdcac2f4f3"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part III: Generate Text"
      ],
      "metadata": {
        "id": "bIApuPIGNCIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a 20 word sentence starting with the word, 'holmes'\n",
        "\n",
        "print(lm.generate(20, text_seed= 'diamond', random_seed=15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9PesEqhNHn4",
        "outputId": "3792b76f-8bf9-459e-f46c-01d39fc7e791"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['your', 'address', 'me', ',', 'â\\x80\\x9d', 'asked', 'me', 'so', 'that', 'â\\x80\\x98for', 'mrs.', 'rucastle', 'suddenly', 'another', 'broad', ',', 'who', 'was', 'speaking', 'only']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "detokenize = TreebankWordDetokenizer().detokenize\n",
        "\n",
        "def generate_sent(lm, num_words, text_seed, random_seed=42):\n",
        "    \"\"\"\n",
        "    :param model: An ngram language model from `nltk.lm.model`.\n",
        "    :param num_words: Max no. of words to generate.\n",
        "    :param random_seed: Seed value for random.\n",
        "    \"\"\"\n",
        "    content = []\n",
        "    for token in lm.generate(num_words, text_seed=text_seed, random_seed=random_seed):\n",
        "        if token == '<s>':\n",
        "            continue\n",
        "        if token == '</s>':\n",
        "            break\n",
        "        content.append(token)\n",
        "    return detokenize(content)"
      ],
      "metadata": {
        "id": "mtg1inVbSzOe"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now generate sentences that look much nicer.\n",
        "generate_sent(lm, 40, text_seed='diamond', random_seed=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Uy-wmpomVy2D",
        "outputId": "4ec5a804-f661-42e1-d468-67aed814fcca"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'your address me, â\\x80\\x9d asked me so that â\\x80\\x98for mrs. rucastle suddenly another broad, who was speaking only trust that her husband already.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_sent(lm, 20, text_seed='sherlock', random_seed = 93)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VuWeLH1HS7di",
        "outputId": "ec3c517e-7080-4d0a-9680-53b1a4493c3c"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'which it may depend so far as either end, mr. fowler.â\\x80\\x9d â\\x80\\x9cthat is too lateâ\\x80\\x99â\\x80\\x9d] â\\x80\\x9cit must stop'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_sent(lm, 30, text_seed='card', random_seed = 17)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CFbWCHAbXUb1",
        "outputId": "7c7ce76e-6001-4071-c5df-d0769b489f6c"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'is the wild and the push her again, fresh information as little fortune to waterloo bridge road, when we canâ\\x80\\x99t make myself with a minute or six hundred'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_sent(lm, 50, text_seed='violin', random_seed = 312)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nhw4m2C3ZRyR",
        "outputId": "b94a5e2e-1f12-4005-fa7e-d197df780cce"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'one of a couple of dubious and it would not finished.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    }
  ]
}